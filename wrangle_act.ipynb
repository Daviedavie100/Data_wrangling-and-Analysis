{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "There are three different types of data for this project, each with different data format. \n",
    "\n",
    "    1) WeRateDogs twitter archive data in a csv format\n",
    "    2) Tweet image prediction in tsv format\n",
    "    3) WeRateDogs twitter account additional datatweet to be stored as tweet_json.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load imports for data gathering\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd # loads pandas library\n",
    "import requests # loads requests library\n",
    "import json # loads json library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Directly download the WeRateDogs Twitter archive data (**twitter_archive_enhanced.csv**)\n",
    "\n",
    "According to Udacity, WeRateDogs downloaded their Twitter archive and sent it to Udacity via email exclusively for you to use in this project. The archive contains basic tweet data for over 5000 of their tweets as they stood on August 1, 2017.\n",
    "\n",
    "I downloaded csv file provided via the link, and then uploaded into my working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_archive_enhanced.csv\n",
    "path=\"C:/Users/Davie/Documents/GitHub/data_wrangling/data/\"\n",
    "twitter_archive=pd.read_csv(path + 'twitter_archive_enhanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "**'twitter-archive-enhanced.csv'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Use the Requests library to download the tweet image prediction (**image_predictions.tsv**)\n",
    "\n",
    "The WeRateDogs tweet image predictions is hosted on Udacityâ€™s servers and is to be downloaded programmatically using requests library via url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url for image_predictions.tsv\n",
    "file_url='https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "# store resquest response in tsv_response\n",
    "tsv_response=requests.get(file_url)\n",
    "# write the response to 'image_predictions.tsv'\n",
    "with open('image_predictions.tsv', 'w') as f:\n",
    "    f.write(tsv_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'image_predictions.tsv'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Use the Tweepy library to query additional data via the Twitter API (**tweet_json.txt**)\n",
    "\n",
    "There are two methods of getting this additional data. Either, through Twitter API and the python tweepy library or direct download of txt file provided by the udacity in the classroom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication process to use Tweepy API\n",
    "consumer_key = 'HIDDEN'\n",
    "consumer_secret = 'HIDDEN'\n",
    "access_token = 'HIDDEN'\n",
    "access_secret = 'HIDDEN'\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of tweet ids\n",
    "tweet_id = twitter_archive['tweet_id']\n",
    "list(tweet_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I successfuly applied for Twitter API v2 Essential, but it has limitated usage. I am unable to use it to acquire the data. Therefore, i have requested for Elevation but not yet approved.\n",
    "\n",
    "- I downloaded the tweet_json.txt provided in the Udacity classroom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file url\n",
    "file_url='https://video.udacity-data.com/topher/2018/November/5be5fb7d_tweet-json/tweet-json.txt'\n",
    "# store resquest response in txt_response\n",
    "txt_response=requests.get(file_url)\n",
    "# write the response to 'tweet_json.txt'\n",
    "with open('tweet_json.txt', 'w') as f:\n",
    "    f.write(txt_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'tweet_json.txt'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read the tweet_json.txt file by converting each json string into python dictionary and appending them to a twitter_list. Finally, I convert this list of dictionaries to a python pandas DataFrame, which is then stored as tweet_json.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_list = [] # empty list\n",
    "\n",
    "with open('tweet_json.txt', 'r') as file: # create tweet_json.txt\n",
    "# converts every line/json string into dictionary\n",
    "    for line in file:\n",
    "        tweet = json.loads(line)  \n",
    "        tweet_id = tweet['id']\n",
    "        retweet_count = tweet['retweet_count']\n",
    "        fav_count = tweet['favorite_count']\n",
    "# append dictionaries into the empty list\n",
    "        twitter_list.append({'tweet_id':tweet_id, 'retweet_count': retweet_count, 'favorite_count': fav_count})\n",
    "# convert list of dictionaries into panda data frame with atleast \n",
    "# (tweet_id, retweet_count, and favorite_count as per the instruction)        \n",
    "twitter_df = pd.DataFrame(twitter_list, columns = ['tweet_id', 'retweet_count', 'favorite_count'])\n",
    "twitter_df.to_csv('tweet_json.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'tweet_json.csv'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. \n",
    "\n",
    "**Quality issues**\n",
    "\n",
    "- Issues related to the data content (dirty data). We check for four quality diemnsions, completeness, validity, accuracy and consistency.\n",
    "\n",
    "**Tidiness issues**\n",
    "\n",
    "- Issues related to the data structure (messy data). We check whether or not each variable forms a column, each observation forms a row or each type of observational unit forms a table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. visual assessment**\n",
    "    - viewing the data without code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_archive_enhanced.csv\n",
    "twitter_archive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing data (NaN, none)\n",
    "- Non-descriptive columns (source, name, text)\n",
    "- inconsistent rating denominator\n",
    "- Extremely low and high rating numerator\n",
    "- invalid names under name column (a, an, none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'image_predictions.tsv'\n",
    "path=\"C:/Users/Davie/Documents/GitHub/data_wrangling/data/\"\n",
    "image_pred=pd.read_csv(path + 'image_predictions.tsv', sep='\\t')\n",
    "image_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None-descriptive column names for the rating algorithms (p's\tp's_conf\tp's_dog)\n",
    "- Tidyness issues, p1, p2 and p3 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_json.csv\n",
    "path=\"C:/Users/Davie/Documents/GitHub/data_wrangling/data/\"\n",
    "tweet_json=pd.read_csv(path + 'tweet_json.csv')\n",
    "tweet_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- low retweet_count for tweet_id 886267009285017600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. programmatic assessement**\n",
    "\n",
    "    -checking data issues with (code) python methods.We use .sample() .shape, .describe(), .info(), .dtypes, .nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.columns # list all columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.shape # assess the dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.nunique() # assess the number of unique values of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive.info() # assesscheck missing and data types of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive[twitter_archive.duplicated()] # assess duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates, timestamp column data type should be datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess the number of uniques for 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'\n",
    "twitter_archive[['retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many retweets that nedd to be removed according to the project motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names=[] # empty list\n",
    "for names in twitter_archive['name']:\n",
    "    if len(names)<=3: # check if the name has less than 3 characters\n",
    "        list_names.append(names)\n",
    "funny_names=pd.Series(list_names).value_counts() # convert to pandas series and check counts per name\n",
    "funny_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these names ('a','by','not', 'his', 'an', 'all', 'life', 'the')do not appear as valid names. The following cells contain codes used to examine a few of the them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_none=twitter_archive[twitter_archive['name']=='None'] # load texts for dogs having 'None' as the names\n",
    "twitter_archive_none[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the texts may contain dog names and stages, while others contain None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_a=twitter_archive[twitter_archive['name']=='a'] # load texts for dogs having 'a' as the names\n",
    "twitter_archive_a[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'a' is not the correct dog name. Some of the texts contain correct dog names and stages but wrongly extracted, while others contain None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_an=twitter_archive[twitter_archive['name']=='an'] # load texts for dogs having 'an' as the names\n",
    "twitter_archive_an[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'an' is not the correct dog name. Though, some of the texts contain correct dog names but wrongly extracted, while others contain None or correct dog stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_the=twitter_archive[twitter_archive['name']=='the'] # load texts for dogs having 'the' as the names\n",
    "twitter_archive_the[['tweet_id','text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'the' is not the correct dog name. However, the text may or may not contain dog name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_one=twitter_archive[twitter_archive['name']=='one'] # load texts for dogs having 'one' as the names\n",
    "twitter_archive_one[['tweet_id','text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'one' is not the correct dog name. Texts may not contain dog names. puppers wrongly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_all=twitter_archive[twitter_archive['name']=='all'] # load texts for dogs having 'all' as the names\n",
    "twitter_archive_all[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'all' is not the correct dog name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_not=twitter_archive[twitter_archive['name']=='not'] # load texts for dogs having 'not' as the names\n",
    "twitter_archive_not[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'not' isn not the correct dog name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_by=twitter_archive[twitter_archive['name']=='by'] # load texts for dogs having 'by' as the names\n",
    "twitter_archive_by[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by is not the correct dog name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_my=twitter_archive[twitter_archive['name']=='my'] # load texts for dogs having 'my' as the names\n",
    "twitter_archive_my[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name is Zoey, wrongly extracted as 'my'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_old=twitter_archive[twitter_archive['name']=='old'] # load texts for dogs having 'old' as the names\n",
    "twitter_archive_old[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'old' is not the correct dog name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_his=twitter_archive[twitter_archive['name']=='his'] # load texts for dogs having 'his' as the names\n",
    "twitter_archive_his[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct dog name is 'Quizno' and not 'his'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_just=twitter_archive[twitter_archive['name']=='just'] # load texts for dogs having 'just' as the names\n",
    "twitter_archive_just[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'just' is not the correct dog name for this group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_life=twitter_archive[twitter_archive['name']=='life'] # load texts for dogs having 'life' as the names\n",
    "twitter_archive_life[['text', 'name', 'doggo', 'floofer', 'pupper', 'puppo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'life' is not a dog name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These texts do appear to contain the dog's name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred.columns # list all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-descriptive columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred.info() # assess the missing and data types for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tweet_id data type is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred.nunique() # assess the unique values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 2075 tweet only 2009 had unique image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred[image_pred['jpg_url'].duplicated()].jpg_url.head(10) # assess duplicate image url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "66 urls are repeated, pointing to the same image. I want to assess url with id 1315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred[image_pred['jpg_url']=='https://pbs.twimg.com/media/CWza7kpWcAAdYLc.jpg'] # assess duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two image url's are the same and show the same image when clicked. The information about the rating algorithm is also the same, except the tweet_id. \n",
    "\n",
    "We need a unique tweet-id with a unique image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred[image_pred.duplicated()] # assess duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicate tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_sorted=image_pred.p1.sort_values() # assess the values under p1-golden retriever\n",
    "p1_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_sorted=image_pred.p2.sort_values() # assess the values under p2-labrador retriever\n",
    "p2_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two columns contains similar items, they are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.shape # assess the dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.columns # list the columns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.info() # assess the missing values and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.describe() # assess the descriptive statistics for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum value is zero in both retweet_count and favorite _count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json[tweet_json.duplicated()] # assess duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicate observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.retweet_count.value_counts().tail(10) # assess the counts for each value in column retweet_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One observation with zero value, did not get a retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json[tweet_json['retweet_count']==0] # find the observation with value zero in the retweet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json.favorite_count.value_counts().head(10) # assess the counts for each value in column favorite_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "179 observations have zero values, the tweets had no favourite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_json[tweet_json['favorite_count']==0].head() # find the observation with value zero in the favorite_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "\n",
    "1.Missing values in twitter_archive data for name column 'None'\n",
    "\n",
    "2.Inaccurate values (dog names) in twitter_archive data for name column ('a', 'an', 'all', 'my', 'not', 'the', 'by', 'such', 'his', 'life', 'one', 'old', 'just')\n",
    "\n",
    "3.181 rows with retweets in twitter archive data, and extreaneous columns need to be removed as per the project motivation\n",
    "\n",
    "4.Missing values in twitter_archive data for the dog stages column 'None' \n",
    "\n",
    "5.The Tweet image prediction, has unique tweet_id but not image url, which is duplicated\n",
    " \n",
    "6.Non-descriptive columns in twitter archive data ('name', 'text')\n",
    "\n",
    "7.The values in image predictions under columns p1, p2, p3 are uppercase\n",
    "\n",
    "8.Incorrect data types:'timestamp', 'retweeted_status_timestamp' datatype is of string\n",
    "\n",
    "9.Incorrect data types for 'tweet_id, retweeted_status_id', retweeted_status_user_id, in_reply_to_status_id, in_reply_to_user_id\n",
    "\n",
    "10.Inconsistent rating denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "\n",
    "1.The four columns for doggo, floofer, pupper, and puppo are dog stages, one variable\n",
    "\n",
    "2.The tweet_id information in all data sets tweet_json.csv, witter archive data and tweet image prediction are related, hence same observational unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "\n",
    "Thuis aims to improve the quality and tidiness by correcting the inaccuracies, removing the irrelevant columns, renaming columns and replacing missing values, or droping rows with the missing values based on the assessment already done\n",
    "\n",
    "Cleaning data uses programmatic data cleaning process, in which every issue identified in the assessment section is first defined followed by codng and testing.\n",
    "\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n",
    "twitter_archive_clean_a=twitter_archive.copy()\n",
    "image_predictions_clean=image_pred.copy()\n",
    "tweet_json_clean=tweet_json.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1: Missing values in twitter_archive data for name column 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Replace the \"None\" with corectly extracted names or with NaN using .str.extract() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select observations where name is not \"None\"\n",
    "twitter_archive_clean_b=twitter_archive_clean_a[twitter_archive_clean_a.name !='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns to extract correct names and dog stages\n",
    "name_pattern='(?:name(?:d)?)\\s{1}(?:is\\s)?([A-Za-z]+)|(?:This(?:d)?)\\s{1}(?:is\\s)([A-Za-z]+)|(?:Meet(?:d)?)\\s{1}(?:\\s)?([A-Za-z]+)|(?:hello(?:d)?)\\s{1}(?:to\\s)([A-Za-z]+)|(?:call(?:d)?)\\s{1}(?:him\\s)([A-Za-z]+)'\n",
    "stage_pattern='(?i)(pupper|doggo|puppo|floofer)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_c=twitter_archive_clean_a[twitter_archive_clean_a.name =='None'].copy() # filter observations whose name is None and make a copy\n",
    "twitter_archive_clean_c['name']=twitter_archive_clean_c['text'].str.extract(name_pattern, expand=True) # extract correct name from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_d=twitter_archive_clean_b.append(twitter_archive_clean_c, ignore_index=True) # join the data tables \n",
    "twitter_archive_clean_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_d.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2: Inaccurate values (dog names) in twitter_archive data for name column ('a', 'an', 'all', 'my', 'not', 'the', 'by', 'such', 'his', 'life', 'one', 'old', 'just')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Replace ('a', 'an', 'all',  'not', 'the', 'by', 'such', 'life', 'one', 'old', 'just') with NaN using np.NaN, 'his' with 'Quizno' and 'my' with 'Zoey' using replace() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_replaced=['a', 'an', 'all', 'not', 'the', 'by', 'such', 'life', 'one', 'old', 'just'] # group the values to be replaced\n",
    "twitter_archive_clean_d['name']=twitter_archive_clean_d['name'].replace(to_be_replaced,np.NaN) # replace the values with NaN\n",
    "twitter_archive_clean_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_d['name']=twitter_archive_clean_d['name'].replace(['my','his'], ['Zoey', 'Quizno']) # correct my and his names with Zoey and Quizno respectively\n",
    "twitter_archive_clean_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_d.name.value_counts() # check whether the names replaced still exist in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: The four columns for doggo, floofer, pupper, and puppo for twitter_archive data are dog stages, one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: In twitter_arvive data, melt doggo, floofer, pupper, and puppo columns into one column called dog_stage using .melt() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmelted_col=['tweet_id', 'timestamp', 'text', 'retweeted_status_id', 'retweeted_status_user_id', \n",
    "              'in_reply_to_status_id', 'in_reply_to_user_id','expanded_urls', 'rating_numerator', \n",
    "              'rating_denominator', 'name'] # create columns not to be melted\n",
    "twitter_archive_clean_e=twitter_archive_clean_d.melt(id_vars=unmelted_col, value_vars=['doggo', 'floofer', 'pupper',\n",
    "       'puppo'], var_name='to_be_removed', value_name='dog_stage') # melt 'doggo', 'floofer', 'pupper','puppo' into dog_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_e.drop('to_be_removed', axis=1, inplace=True) # drop column to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_e.drop_duplicates(inplace=True) # drops duplicates from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twitter_archive_clean_e.columns)==len(twitter_archive_clean_e.columns) # should return false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean_e.dog_stage.value_counts() # assess the observations under dog stage column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: Missing values in twitter_archive data for the dog stages column 'None' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Replace None with the correct extracted dog_stage from the text or with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean=twitter_archive_clean_e.copy() # make copy\n",
    "twitter_archive_clean['dog_stage']=twitter_archive_clean['text'].str.extract(stage_pattern, expand=True) # use regex pattern to extract the correct dog stage names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.dog_stage.value_counts() # assess the new observations under dog stage column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_caps=['Doggo','Floofer', 'PUPPER', 'Puppo', 'DOGGO', 'Pupper'] # create names in caps to be corrected\n",
    "cor_stage=['doggo', 'floofer', 'pupper', 'puppo', 'doggo', 'pupper'] # correct names\n",
    "twitter_archive_clean['dog_stage']=twitter_archive_clean['dog_stage'].replace(stage_caps,cor_stage) # replace the names in caps with the correct ones\n",
    "twitter_archive_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.dog_stage.value_counts() # assess the observations under new dog stage column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_clean.head() # load new twitter_archive_clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5: Some values in image predictions data under p1, p2 , and p2 columns are in uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:Make the values of columns p1, p2, p3 in predictions all lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_clean['p1'] = image_predictions_clean['p1'].str.lower() # converts values in p1 to lowercase\n",
    "image_predictions_clean['p2'] = image_predictions_clean['p2'].str.lower() # converts values in p2 to lowercase\n",
    "image_predictions_clean['p3'] = image_predictions_clean['p3'].str.lower() # converts values in p3 to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions_clean.p1.unique()\n",
    "image_predictions_clean.p2.unique()\n",
    "image_predictions_clean.p3.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #6: The tweet_id information in all data sets tweet_json.csv, witter archive data and tweet image prediction are relerated, hence same observational unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define: Merge the three datasets, weet_json.csv, witter archive data and tweet image prediction into one table called twitter_archive_master using merge() method on tweet_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first merge twitter_archive_clean to image_predictions_clean\n",
    "twitter_archive_master_a=image_predictions_clean.merge(twitter_archive_clean, on='tweet_id', how='inner')\n",
    "twitter_archive_master_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second merge twitter_json_clean to twitter_archive_master_a\n",
    "twitter_archive_master_b=twitter_archive_master_a.merge(tweet_json_clean, on='tweet_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase number of visible columns in a pandas DataFrame to see all the columns in the newly created twitter_archive_master_b\n",
    "pd.set_option(\"display.max_columns\",25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_b.columns # should return more number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #7: 181 rows with retweets in twitter archive data, need to be removed as per the project motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Remove 181 rows with retweets as well as extraneous columns 'in_reply_to_status_id', 'in_reply_to_user_id','source', 'retweeted_status_id', 'retweeted_status_user_id','retweeted_status_timestamp' by filtering them out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 181 retweets found in \"retweeted_status_id\", \"retweeted_status_user_id\" and \"retweeted_status_timestamp\". We keep the rows that are null and remove the retweets.\n",
    "twitter_archive_master_c = twitter_archive_master_b[twitter_archive_master_b.retweeted_status_id.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extraneous columns\n",
    "cols=['tweet_id', 'jpg_url', 'img_num', 'p1', 'p1_conf', 'p1_dog', 'p2','p2_conf', 'p2_dog', 'p3', \n",
    "      'p3_conf', 'p3_dog', 'timestamp', 'text', 'expanded_urls','rating_numerator', 'rating_denominator', \n",
    "      'name', 'dog_stage','retweet_count', 'favorite_count'] # group the columns to be filtered\n",
    "twitter_archive_master_d=twitter_archive_master_c.filter(cols, axis=1) # filter the required columns\n",
    "twitter_archive_master_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_d.columns # assess the filtered columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #8: The Tweet image prediction, has unique tweet_id but not image url, which is duplicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Remove duplicate jpg_url in tweet image prediction data, to get a unique tweet-id with a unique jpg_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_e=twitter_archive_master_d.drop_duplicates(subset=['jpg_url']) # remove duplicates based on jpg_url column\n",
    "twitter_archive_master_e.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master_e.shape==twitter_archive_master_d.shape # should return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #9: Non-descriptive columns names  ('name', 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Rename the column 'name' as 'dog_name'  and 'text' as 'tweets_text' in the twitter_archive_master using .rename() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change name to dog name and text to tweets_text\n",
    "twitter_archive_master=twitter_archive_master_e.copy()\n",
    "twitter_archive_master.rename(columns={'name': 'dog_name', 'text': 'tweet_text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if twitter_archive_master.columns.any()=='dog_name' or 'tweet_text': # check if any column contains dog_name or tweet_text\n",
    "    print('Yes') # should return yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #10: None-descriptive column names in tweet image prediction data for the rating algorithms ('jpg_url', 'img_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Rename the column 'jpg_url', and 'img_num', in the twitter_archive_master using .rename() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict={'jpg_url':'image_link', 'img_num':'number_of_images'} # create dictionary for old and new names\n",
    "twitter_archive_master.rename(columns=rename_dict, inplace=True) # rename the coumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.columns # check the columns in the new data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.head() # load the twitter_archive_master data table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #11: Incorrect data types for  'timestamp', datatype is of string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Convert 'timestamp' data type to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master['timestamp']=pd.to_datetime(twitter_archive_master['timestamp']) # convert timestamp into datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master['timestamp'].dtypes # assess the data type for timestamp, should return '<M8[ns]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #12: Incorrect data types for 'tweet_id, retweeted_status_id', retweeted_status_user_id, in_reply_to_status_id, in_reply_to_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Convert 'tweet_id' to string type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master['tweet_id']=twitter_archive_master['tweet_id'].astype(str) # convert tweet_id to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create order of indexing of the columns\n",
    "column_names = ['tweet_id', 'timestamp', 'dog_name', 'dog_stage','retweet_count', 'favorite_count', \n",
    "                'rating_numerator', 'rating_denominator', 'p1', 'p1_conf','p1_dog', 'p2','p2_conf', \n",
    "                'p2_dog', 'p3', 'p3_conf', 'p3_dog','image_link', 'number_of_images','tweet_text', 'expanded_urls']\n",
    "\n",
    "twitter_archive_master = twitter_archive_master.reindex(columns=column_names) # reorder the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.drop_duplicates(inplace=True) # remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master['tweet_id'].dtypes # should return O, object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.shape # assess the shape of twitter_archive_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.to_csv('twitter_archive_master.csv', index=False) # store twitter_archive_master dataframe to a csv file named twitter_archive_master.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master=pd.read_csv('twitter_archive_master.csv') # load twitter_archive_master.csv into pandas dataframe\n",
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1.Pupper dog stage is the most popular dog stage amongst WeRateDogsâ€™s tweets, favorite and retweets counts. The second, most popular dog stage based on the retweets and favorite counts is doggo. \n",
    "\n",
    "2.There is strong linear relationship between the Favourites count and the Retweet, though most of the data is accumulated at the start. This relationship is the same in every dog stage. Also, the distribution for p1, p2 and p3 is really skewed\n",
    "\n",
    "3.Golden Retriever is the most popular dog breed amongst WeRateDogsâ€™s tweets in terms of the number of image predictions having 139 dogs. The second most popular dog breed is Labrador Retriever also having 95 dogs. Therefore, golden retriever, labrador retriever, pembroke, Chihuahua and pug make top 5 most popular dog breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=twitter_archive_master.groupby(['dog_stage']).retweet_count.sum().sort_values()\n",
    "#twitter_archive_master.dog_stage.value_counts()\n",
    "labels=['floofer', 'puppo', 'doggo', 'pupper']\n",
    "\n",
    "plt.rcParams['font.size'] = '16'\n",
    "fig, ax=plt.subplots(figsize=[10,14])\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "#explode = (0, 0, 0.2, 0.1)\n",
    "plt.pie(values, labels=labels, counterclock=False, autopct='%1.1f%%') #explode=explode,  shadow=True, \n",
    "plt.title('Dog Stage Popularity Chart-Retweet Counts', fontsize=20)\n",
    "plt.legend(labels, loc=2)\n",
    "\n",
    "# Save the plot as a JPG file\n",
    "plt.savefig('dog_stage_popularity_chart.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retweet counts pie chart shows that the most popular dog stage is pupper, which is has 42.5 percent populaity. The second is doggo, followed by puppo and lastly floofer, whose popularity is 2.8 percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=twitter_archive_master.groupby(['dog_stage']).favorite_count.sum().sort_values()\n",
    "#twitter_archive_master.dog_stage.value_counts()\n",
    "labels=['floofer', 'puppo', 'doggo', 'pupper']\n",
    "\n",
    "plt.rcParams['font.size'] = '12'\n",
    "fig, ax=plt.subplots(figsize=[10,14])\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "#explode = (0, 0.1, 0.2, 0.1)\n",
    "plt.pie(values, labels=labels, counterclock=False, autopct='%1.1f%%') #explode=explode,\n",
    "plt.title('Dog Stage Popularity Chart based on Favorite Counts', fontsize=20)\n",
    "plt.legend(labels, loc=4)\n",
    "\n",
    "# Save the plot as a JPG file\n",
    "plt.savefig('dog_stage_popularity_chartFa.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, favorite counts pie chart still shows that the most popular dog stage is pupper with popularity at 43.8 percent, which 1.3 percent increase from the previous pie chart. Doggo is still second most popular dog stage, the percentage has reduced from 39.3 percent for retweet counts to 36.1 percent for favourite counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.groupby(['dog_stage']).favorite_count.sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above output, pupper dog stage has the highest sum of of favorite counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatter plot for Retweet Counnts vs favorite Counnts\n",
    "x=twitter_archive_master.retweet_count\n",
    "y=twitter_archive_master.favorite_count\n",
    "\n",
    "fig, ax=plt.subplots(figsize=[10, 6])\n",
    "plt.rcParams['font.size'] = '14' # Set general font size\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "plt.scatter(x,y,color='blue')\n",
    "plt.title('Scatter plot for Retweet Counnts vs Favorite Counnts')\n",
    "plt.xlabel('Retweet Counnts')\n",
    "plt.ylabel('Favorite Counnts')\n",
    "\n",
    "# Save the plot as a JPG file\n",
    "plt.savefig('scatter_R_and_F.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is strong linear correlation between retweet counnts and favorite counnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatter plots for retweet counnts and favorite counnts for each dog stage\n",
    "x1=twitter_archive_master[twitter_archive_master.dog_stage=='pupper'].retweet_count\n",
    "y1=twitter_archive_master[twitter_archive_master.dog_stage=='pupper'].favorite_count\n",
    "\n",
    "x2=twitter_archive_master[twitter_archive_master.dog_stage=='doggo'].retweet_count\n",
    "y2=twitter_archive_master[twitter_archive_master.dog_stage=='doggo'].favorite_count\n",
    "\n",
    "x3=twitter_archive_master[twitter_archive_master.dog_stage=='puppo'].retweet_count\n",
    "y3=twitter_archive_master[twitter_archive_master.dog_stage=='puppo'].favorite_count\n",
    "\n",
    "x4=twitter_archive_master[twitter_archive_master.dog_stage=='floofer'].retweet_count\n",
    "y4=twitter_archive_master[twitter_archive_master.dog_stage=='floofer'].favorite_count\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = False\n",
    "plt.rcParams['font.size'] = '14' # Set general font size\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "labels='pupper'\n",
    "plt.scatter(x1,y1, color='green')\n",
    "plt.title('Scatter plot for Pupper')\n",
    "plt.xlabel('Retweet Counnts')\n",
    "plt.ylabel('Favorite Counnts')\n",
    "plt.legend([labels], loc=0)\n",
    "\n",
    "plt.savefig('scatter_for_pupper.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = False\n",
    "plt.rcParams['font.size'] = '14' # Set general font size\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "labels='doggo'\n",
    "plt.scatter(x2,y2,color='blue')\n",
    "plt.title('Scatter plot for Doggo')\n",
    "plt.xlabel('Retweet Counnts')\n",
    "plt.ylabel('Favorite Counnts')\n",
    "plt.legend([labels], loc=0)\n",
    "\n",
    "plt.savefig('scatter_for_doggo.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = False\n",
    "plt.rcParams['font.size'] = '14' # Set general font size\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "labels='puppo'\n",
    "plt.scatter(x3,y3,color='orange')\n",
    "plt.title('Scatter plot for Puppo')\n",
    "plt.xlabel('Retweet Counnts')\n",
    "plt.ylabel('Favorite Counnts')\n",
    "plt.legend([labels], loc=0)\n",
    "\n",
    "plt.savefig('scatter_for_puppo.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.autolayout\"] = False\n",
    "plt.rcParams['font.size'] = '14' # Set general font size\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "labels='floofer'\n",
    "plt.scatter(x4,y4,color='black')\n",
    "plt.title('Scatter plot for Floofer')\n",
    "plt.xlabel('Retweet Counnts')\n",
    "plt.ylabel('Favorite Counnts')\n",
    "plt.legend([labels], loc=0)\n",
    "\n",
    "plt.savefig('scatter_for_floofer.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, there is strong linear correlation between retweet counnts and favorite counnts for each dog stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatter matrix\n",
    "histogram=twitter_archive_master[['p1_conf','p2_conf','p3_conf']]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams['font.size'] = '14' # Set general font size\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "pd.plotting.scatter_matrix(histogram, color='black', alpha=0.7)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.savefig('scatter_matrix.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions are all skewed. p1 is left skewed, while p2 and p3 are right skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to get the most common dog breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_breed_type=twitter_archive_master.copy() # make copy of twitter_archive_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put p1, p2 and p3 into one group known as breed type using melt method\n",
    "twitter_archive_breed_type=twitter_archive_breed_type.melt(id_vars=['tweet_id', 'timestamp', 'dog_name', 'dog_stage','retweet_count', 'favorite_count', \n",
    "                 'rating_numerator', 'rating_denominator','p1_conf','p1_dog','p2_conf', \n",
    "                 'p2_dog', 'p3_conf', 'p3_dog','image_link', 'number_of_images',\n",
    "                     'tweet_text', 'expanded_urls'], \n",
    "            value_vars=['p1', 'p2', 'p3'], \n",
    "            var_name='to_be_removed1', value_name='breed_type')\n",
    "twitter_archive_breed_type.drop('to_be_removed1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_breed_type.drop_duplicates(inplace=True) # remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_breed=twitter_archive_breed_type.copy() # make copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put 'p1_dog', 'p2_dog', 'p3_dog' into one column called breed using melt method\n",
    "twitter_archive_breed=twitter_archive_breed_type.melt(id_vars=['tweet_id', 'timestamp', 'dog_name', 'dog_stage','retweet_count', 'favorite_count', \n",
    "                 'rating_numerator', 'rating_denominator','p1_conf','p2_conf', 'p3_conf', \n",
    "                                                          'image_link', 'number_of_images',\n",
    "                     'tweet_text', 'expanded_urls', 'breed_type'], \n",
    "            value_vars=['p1_dog', 'p2_dog', 'p3_dog'], \n",
    "            var_name='to_be_removed2', value_name='breed')\n",
    "twitter_archive_breed.drop('to_be_removed2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_breed.drop_duplicates(subset='tweet_id',inplace=True) # remove duplicates if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only those which are dog breed\n",
    "breed=twitter_archive_breed[twitter_archive_breed.breed==True].breed_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=['green', 'red', 'yellow', 'blue', 'black', 'orange', 'violet', 'brown', 'indigo', 'pink']\n",
    "breed[breed>27].reset_index()\n",
    "#reindex(['breed type', 'count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "fig.patch.set_facecolor('white')  # Set figure background to white\n",
    "\n",
    "# Filter and reset index\n",
    "filtered_breed = breed[breed > 27].reset_index()\n",
    "filtered_breed.columns = ['index', 'breed_type']  # Ensure proper column names\n",
    "\n",
    "# Create the barplot\n",
    "catplot = sb.catplot(\n",
    "    data=filtered_breed, \n",
    "    kind='bar', \n",
    "    y='index', \n",
    "    x='breed_type', \n",
    "    palette='viridis', \n",
    "    height=6,  # Adjust height of the plot\n",
    "    aspect=1.5  # Adjust aspect ratio\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "catplot.ax.set_title('Top 10 Dog Breeds', fontsize=16, fontweight='bold')\n",
    "catplot.ax.set_xlabel('Frequency', fontsize=12)\n",
    "catplot.ax.set_ylabel('Dog Breed', fontsize=12)\n",
    "\n",
    "plt.savefig('top10dogs.jpg', format='jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common dog breed is golden retriever, interms of the number of image predictions. The second most popular dog breed is Labrador Retriever, followed by Pembroke and finaly by Chihuahua"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "uscholar_py3.6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
